{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-08T14:31:18.256706Z",
     "iopub.status.busy": "2024-07-08T14:31:18.256258Z",
     "iopub.status.idle": "2024-07-08T14:31:18.262177Z",
     "shell.execute_reply": "2024-07-08T14:31:18.260874Z",
     "shell.execute_reply.started": "2024-07-08T14:31:18.256671Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:31:19.746478Z",
     "iopub.status.busy": "2024-07-08T14:31:19.746054Z",
     "iopub.status.idle": "2024-07-08T14:31:19.827649Z",
     "shell.execute_reply": "2024-07-08T14:31:19.826259Z",
     "shell.execute_reply.started": "2024-07-08T14:31:19.746445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boont\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\boont\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('spam_classifier_model.pkl', 'rb') as file:\n",
    "    model1 = pickle.load(file)\n",
    "\n",
    "\n",
    "with open('count_vectorizer.pkl', 'rb') as file:\n",
    "    count = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:31:23.807787Z",
     "iopub.status.busy": "2024-07-08T14:31:23.807344Z",
     "iopub.status.idle": "2024-07-08T14:31:23.818825Z",
     "shell.execute_reply": "2024-07-08T14:31:23.817485Z",
     "shell.execute_reply.started": "2024-07-08T14:31:23.807752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def checkSpam(df):\n",
    "    if df.empty or 'email_text' not in df.columns:\n",
    "        raise ValueError(\"DataFrame is empty or does not contain 'email_text' column.\")\n",
    "    \n",
    "    email_text = df.iloc[0]['email_text']\n",
    "    email_vector = count.transform([email_text])\n",
    "    prediction = model1.predict(email_vector.toarray())\n",
    "    return prediction[0] == 1  \n",
    "data = {\n",
    "    'email_text': [\n",
    "        \"Subject: Greetings, My name is Kuan Tian\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "is_spam = checkSpam(df)\n",
    "print(is_spam)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:32:27.680288Z",
     "iopub.status.busy": "2024-07-08T14:32:27.679130Z",
     "iopub.status.idle": "2024-07-08T14:32:42.820959Z",
     "shell.execute_reply": "2024-07-08T14:32:42.819361Z",
     "shell.execute_reply.started": "2024-07-08T14:32:27.680242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\boont\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\boont\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\boont\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\boont\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\boont\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\boont\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:32:47.236091Z",
     "iopub.status.busy": "2024-07-08T14:32:47.235579Z",
     "iopub.status.idle": "2024-07-08T14:32:47.243064Z",
     "shell.execute_reply": "2024-07-08T14:32:47.241614Z",
     "shell.execute_reply.started": "2024-07-08T14:32:47.236039Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:32:52.678651Z",
     "iopub.status.busy": "2024-07-08T14:32:52.678183Z",
     "iopub.status.idle": "2024-07-08T14:34:14.433775Z",
     "shell.execute_reply": "2024-07-08T14:34:14.432266Z",
     "shell.execute_reply.started": "2024-07-08T14:32:52.678615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find either /usr/share/nltk_data/corpora/wordnet.zip or /usr/share/nltk_data/corpora/wordnet.zip.zip.\n"
     ]
    }
   ],
   "source": [
    "# Used to install wordnet lemmatizer\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:34:15.673190Z",
     "iopub.status.busy": "2024-07-08T14:34:15.672735Z",
     "iopub.status.idle": "2024-07-08T14:34:15.680363Z",
     "shell.execute_reply": "2024-07-08T14:34:15.679092Z",
     "shell.execute_reply.started": "2024-07-08T14:34:15.673150Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:29:57.222964Z",
     "iopub.status.busy": "2024-07-08T14:29:57.221844Z",
     "iopub.status.idle": "2024-07-08T14:29:57.231369Z",
     "shell.execute_reply": "2024-07-08T14:29:57.229891Z",
     "shell.execute_reply.started": "2024-07-08T14:29:57.222922Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:34:19.380682Z",
     "iopub.status.busy": "2024-07-08T14:34:19.380292Z",
     "iopub.status.idle": "2024-07-08T14:34:19.803184Z",
     "shell.execute_reply": "2024-07-08T14:34:19.802046Z",
     "shell.execute_reply.started": "2024-07-08T14:34:19.380650Z"
    }
   },
   "outputs": [],
   "source": [
    "msg_useful_terms_without_digit = pd.read_csv(\"msg_useful_terms_without_digit.csv\")\n",
    "msg_useful_terms_without_digit.replace(to_replace = np.nan, value = \"\", inplace=True)\n",
    "\n",
    "thread_term_weights = pd.read_csv(\"thread_term_weights.csv\")\n",
    "thread_term_weights.replace(to_replace = np.nan, value = \"\", inplace=True)\n",
    "\n",
    "thread_weights = pd.read_csv(\"thread_weights.csv\")\n",
    "thread_weights.replace(to_replace = np.nan, value = \"\", inplace=True)\n",
    "\n",
    "df = pd.read_csv(\"testset.csv\")\n",
    "df.replace(to_replace = np.nan, value = \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "      <th>email_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Text FA to 87121 to receive entry question(std...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WINNER!!</td>\n",
       "      <td>As a valued network customer you have been sel...</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FreeMsg</td>\n",
       "      <td>Hey there darling it's been 3 week's now and n...</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had your mobile 11 months or more?</td>\n",
       "      <td>U R entitled to Update to the latest colour mo...</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIX chances to win CASH!</td>\n",
       "      <td>From 100 to 20,000 pounds txt&gt; CSH11 and send ...</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>oasis transport imbalance update</td>\n",
       "      <td>I have attached the draft policy for your revi...</td>\n",
       "      <td>oasis transport imbalance update I have attach...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>new book theory financial risk update</td>\n",
       "      <td>Please find the attached project timeline and ...</td>\n",
       "      <td>new book theory financial risk update Please f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>start date hourahead hour update</td>\n",
       "      <td>The audit report is attached. Please review an...</td>\n",
       "      <td>start date hourahead hour update The audit rep...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>call note update</td>\n",
       "      <td>I have attached the meeting agenda for your re...</td>\n",
       "      <td>call note update I have attached the meeting a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>telephone interview enron corp research update</td>\n",
       "      <td>Please see the attached project update and pro...</td>\n",
       "      <td>telephone interview enron corp research update...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               subject  \\\n",
       "0    Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "1                                             WINNER!!   \n",
       "2                                              FreeMsg   \n",
       "3                   Had your mobile 11 months or more?   \n",
       "4                            SIX chances to win CASH!    \n",
       "..                                                 ...   \n",
       "103                   oasis transport imbalance update   \n",
       "104              new book theory financial risk update   \n",
       "105                   start date hourahead hour update   \n",
       "106                                   call note update   \n",
       "107     telephone interview enron corp research update   \n",
       "\n",
       "                                               content  \\\n",
       "0    Text FA to 87121 to receive entry question(std...   \n",
       "1    As a valued network customer you have been sel...   \n",
       "2    Hey there darling it's been 3 week's now and n...   \n",
       "3    U R entitled to Update to the latest colour mo...   \n",
       "4    From 100 to 20,000 pounds txt> CSH11 and send ...   \n",
       "..                                                 ...   \n",
       "103  I have attached the draft policy for your revi...   \n",
       "104  Please find the attached project timeline and ...   \n",
       "105  The audit report is attached. Please review an...   \n",
       "106  I have attached the meeting agenda for your re...   \n",
       "107  Please see the attached project update and pro...   \n",
       "\n",
       "                                            email_text  label  \n",
       "0    Free entry in 2 a wkly comp to win FA Cup fina...      0  \n",
       "1    WINNER!! As a valued network customer you have...      0  \n",
       "2    FreeMsg Hey there darling it's been 3 week's n...      0  \n",
       "3    Had your mobile 11 months or more? U R entitle...      0  \n",
       "4    SIX chances to win CASH! From 100 to 20,000 po...      0  \n",
       "..                                                 ...    ...  \n",
       "103  oasis transport imbalance update I have attach...      2  \n",
       "104  new book theory financial risk update Please f...      2  \n",
       "105  start date hourahead hour update The audit rep...      2  \n",
       "106  call note update I have attached the meeting a...      2  \n",
       "107  telephone interview enron corp research update...      2  \n",
       "\n",
       "[108 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(search_term, weight_df, term=True):\n",
    "    if (len(search_term)>0):\n",
    "        if term:\n",
    "            term_match = False\n",
    "            for search_item in search_term:\n",
    "                match = weight_df[\"term\"] == search_item\n",
    "                term_match = term_match | match\n",
    "        else:\n",
    "            term_match = weight_df.subject.str.contains(search_term, regex=False)\n",
    "        \n",
    "        match_weights = weight_df.weight[term_match]\n",
    "        if len(match_weights)<1:\n",
    "            return 1\n",
    "        else:\n",
    "            return match_weights.mean()\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:34:22.517661Z",
     "iopub.status.busy": "2024-07-08T14:34:22.517237Z",
     "iopub.status.idle": "2024-07-08T14:34:22.528111Z",
     "shell.execute_reply": "2024-07-08T14:34:22.526726Z",
     "shell.execute_reply.started": "2024-07-08T14:34:22.517627Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_message(msg):        \n",
    "    # Then, from thread activity\n",
    "    is_thread = len(msg.subject.split('re ')) > 1\n",
    "    if is_thread:\n",
    "        subject = msg.subject.split('re ')[1]\n",
    "        msg_thread_activity_wt = get_weights(subject, thread_weights, term=False)\n",
    "    else:\n",
    "        msg_thread_activity_wt = 1\n",
    "    \n",
    "    try:\n",
    "        vec = CountVectorizer()\n",
    "        sub_vec = vec.fit_transform([msg['subject']])\n",
    "        msg_thread_terms = vec.get_feature_names_out()\n",
    "        msg_thread_term_wt = get_weights(msg_thread_terms, thread_term_weights)\n",
    "    except:\n",
    "        # Some subjects from the test set result in empty vocabulary\n",
    "        msg_thread_term_wt = 1\n",
    "    \n",
    "    try:\n",
    "        vec = CountVectorizer()\n",
    "        msg_vec = vec.fit_transform([msg['content']])\n",
    "        msg_terms = vec.get_feature_names_out()\n",
    "        msg_terms_wt = get_weights(msg_terms, msg_useful_terms_without_digit)\n",
    "    except:\n",
    "        # Some subjects from the test set result in empty vocabulary\n",
    "        msg_terms_wt = 1\n",
    "    \n",
    "    # Calculating Rank\n",
    "    rank = float(msg_thread_activity_wt) * float(msg_thread_term_wt) * float(msg_terms_wt)\n",
    "    \n",
    "    return rank, msg.subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:34:24.526291Z",
     "iopub.status.busy": "2024-07-08T14:34:24.525764Z",
     "iopub.status.idle": "2024-07-08T14:34:24.535301Z",
     "shell.execute_reply": "2024-07-08T14:34:24.534053Z",
     "shell.execute_reply.started": "2024-07-08T14:34:24.526253Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_words(x):\n",
    "    res = []\n",
    "    for i, word in enumerate(x):\n",
    "        if word.isdigit():\n",
    "            continue\n",
    "        if word not in unwanted_words:\n",
    "            res.append(word)\n",
    "            continue\n",
    "        if i == 0 and (word in [\"re\", \"fw\"]):\n",
    "            res.append(word)\n",
    "            continue\n",
    "    return res\n",
    "\n",
    "unwanted_words = [] + list(nltk.corpus.stopwords.words(\"english\")) + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:30:06.784833Z",
     "iopub.status.busy": "2024-07-08T14:30:06.784402Z",
     "iopub.status.idle": "2024-07-08T14:30:06.790754Z",
     "shell.execute_reply": "2024-07-08T14:30:06.789447Z",
     "shell.execute_reply.started": "2024-07-08T14:30:06.784798Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatization(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"subject\"] = df[\"subject\"].apply(lambda x:x.lower())\n",
    "df[\"content\"] = df[\"content\"].apply(lambda x:x.lower())\n",
    "df[\"subject\"] = df[\"subject\"].apply(nltk.word_tokenize)\n",
    "df[\"content\"] = df[\"content\"].apply(nltk.word_tokenize)\n",
    "# stop word, punctuation, digit removal\n",
    "df[\"subject\"] = df[\"subject\"].apply(remove_unwanted_words)\n",
    "df[\"content\"] = df[\"content\"].apply(remove_unwanted_words)\n",
    "# lemmatization\n",
    "df[\"subject\"] = df[\"subject\"].apply(lemmatization)\n",
    "df[\"subject\"] = df[\"subject\"].apply(\" \".join)\n",
    "df[\"content\"] = df[\"content\"].apply(lemmatization)\n",
    "df[\"content\"] = df[\"content\"].apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "      <th>email_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>free entry wkly comp win fa cup final tkts 21s...</td>\n",
       "      <td>text fa receive entry question std txt rate c ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>winner</td>\n",
       "      <td>valued network customer selected receivea å£90...</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freemsg</td>\n",
       "      <td>hey darling 's week 's word back 'd like fun s...</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobile month</td>\n",
       "      <td>u r entitled update latest colour mobile camer...</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>six chance win cash</td>\n",
       "      <td>20,000 pound txt csh11 send 87575. cost 150p/d...</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>oasis transport imbalance update</td>\n",
       "      <td>attached draft policy review comment please pr...</td>\n",
       "      <td>oasis transport imbalance update I have attach...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>new book theory financial risk update</td>\n",
       "      <td>please find attached project timeline mileston...</td>\n",
       "      <td>new book theory financial risk update Please f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>start date hourahead hour update</td>\n",
       "      <td>audit report attached please review prepare fo...</td>\n",
       "      <td>start date hourahead hour update The audit rep...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>call note update</td>\n",
       "      <td>attached meeting agenda reference please revie...</td>\n",
       "      <td>call note update I have attached the meeting a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>telephone interview enron corp research update</td>\n",
       "      <td>please see attached project update provide fee...</td>\n",
       "      <td>telephone interview enron corp research update...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               subject  \\\n",
       "0    free entry wkly comp win fa cup final tkts 21s...   \n",
       "1                                               winner   \n",
       "2                                              freemsg   \n",
       "3                                         mobile month   \n",
       "4                                  six chance win cash   \n",
       "..                                                 ...   \n",
       "103                   oasis transport imbalance update   \n",
       "104              new book theory financial risk update   \n",
       "105                   start date hourahead hour update   \n",
       "106                                   call note update   \n",
       "107     telephone interview enron corp research update   \n",
       "\n",
       "                                               content  \\\n",
       "0    text fa receive entry question std txt rate c ...   \n",
       "1    valued network customer selected receivea å£90...   \n",
       "2    hey darling 's week 's word back 'd like fun s...   \n",
       "3    u r entitled update latest colour mobile camer...   \n",
       "4    20,000 pound txt csh11 send 87575. cost 150p/d...   \n",
       "..                                                 ...   \n",
       "103  attached draft policy review comment please pr...   \n",
       "104  please find attached project timeline mileston...   \n",
       "105  audit report attached please review prepare fo...   \n",
       "106  attached meeting agenda reference please revie...   \n",
       "107  please see attached project update provide fee...   \n",
       "\n",
       "                                            email_text  label  \n",
       "0    Free entry in 2 a wkly comp to win FA Cup fina...      0  \n",
       "1    WINNER!! As a valued network customer you have...      0  \n",
       "2    FreeMsg Hey there darling it's been 3 week's n...      0  \n",
       "3    Had your mobile 11 months or more? U R entitle...      0  \n",
       "4    SIX chances to win CASH! From 100 to 20,000 po...      0  \n",
       "..                                                 ...    ...  \n",
       "103  oasis transport imbalance update I have attach...      2  \n",
       "104  new book theory financial risk update Please f...      2  \n",
       "105  start date hourahead hour update The audit rep...      2  \n",
       "106  call note update I have attached the meeting a...      2  \n",
       "107  telephone interview enron corp research update...      2  \n",
       "\n",
       "[108 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T14:35:37.790826Z",
     "iopub.status.busy": "2024-07-08T14:35:37.790436Z",
     "iopub.status.idle": "2024-07-08T14:36:30.045117Z",
     "shell.execute_reply": "2024-07-08T14:36:30.043777Z",
     "shell.execute_reply.started": "2024-07-08T14:35:37.790796Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 2\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 3\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 4\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 5\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 6\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 7\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 8\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 9\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 10\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 11\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 12\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 13\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 14\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 15\n",
      "Predict: 2\n",
      "Actual: 0\n",
      "Rank 32.522216553466734\n",
      "\n",
      "Test 16\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 17\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 18\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 19\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 20\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 21\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 22\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 23\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 24\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 25\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 26\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 27\n",
      "Predict: 2\n",
      "Actual: 0\n",
      "Rank 36.71697123858817\n",
      "\n",
      "Test 28\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 29\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 30\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 31\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 32\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 33\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 34\n",
      "Predict: 0\n",
      "Actual: 0\n",
      "\n",
      "Test 35\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 27.34300760274158\n",
      "\n",
      "Test 36\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 32.371174530875635\n",
      "\n",
      "Test 37\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 38\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.479456044066925\n",
      "\n",
      "Test 39\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 36.06105377161383\n",
      "\n",
      "Test 40\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 41\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.796767379166514\n",
      "\n",
      "Test 42\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 37.05166595737995\n",
      "\n",
      "Test 43\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 31.705291746093565\n",
      "\n",
      "Test 44\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 25.876223932207406\n",
      "\n",
      "Test 45\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 46\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 47\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 37.1585615504709\n",
      "\n",
      "Test 48\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 28.3698812109326\n",
      "\n",
      "Test 49\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 27.71863585957661\n",
      "\n",
      "Test 50\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 37.398538350046216\n",
      "\n",
      "Test 51\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 36.62539348151259\n",
      "\n",
      "Test 52\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 32.011514324442906\n",
      "\n",
      "Test 53\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.67307703408687\n",
      "\n",
      "Test 54\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 28.40174003440735\n",
      "\n",
      "Test 55\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.78524105460591\n",
      "\n",
      "Test 56\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 57\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 27.193498561208454\n",
      "\n",
      "Test 58\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 59\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 32.73545712187695\n",
      "\n",
      "Test 60\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 36.397027611815496\n",
      "\n",
      "Test 61\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 32.4440374847478\n",
      "\n",
      "Test 62\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 29.210868536985338\n",
      "\n",
      "Test 63\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 29.007950764567617\n",
      "\n",
      "Test 64\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.813349678347084\n",
      "\n",
      "Test 65\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.625207865927447\n",
      "\n",
      "Test 66\n",
      "Predict: 0\n",
      "Actual: 1\n",
      "\n",
      "Test 67\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 29.27977018142637\n",
      "\n",
      "Test 68\n",
      "Predict: 2\n",
      "Actual: 1\n",
      "Rank 30.290009885302183\n",
      "\n",
      "Test 69\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 32.50452047107213\n",
      "\n",
      "Test 70\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.74579557850873\n",
      "\n",
      "Test 71\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.51271594063881\n",
      "\n",
      "Test 72\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 40.69776335398457\n",
      "\n",
      "Test 73\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 33.44956556097672\n",
      "\n",
      "Test 74\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.231715998354154\n",
      "\n",
      "Test 75\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 42.43263827109763\n",
      "\n",
      "Test 76\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.04229444330685\n",
      "\n",
      "Test 77\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 36.25908506137969\n",
      "\n",
      "Test 78\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.32918604782267\n",
      "\n",
      "Test 79\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.82381157375001\n",
      "\n",
      "Test 80\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.73239327349299\n",
      "\n",
      "Test 81\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 38.5603828080348\n",
      "\n",
      "Test 82\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 36.46392385563615\n",
      "\n",
      "Test 83\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.860985452361305\n",
      "\n",
      "Test 84\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.57418781190096\n",
      "\n",
      "Test 85\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.68446696692736\n",
      "\n",
      "Test 86\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 36.72594487636994\n",
      "\n",
      "Test 87\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 33.01308582816874\n",
      "\n",
      "Test 88\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.10381151338038\n",
      "\n",
      "Test 89\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 36.97069875389997\n",
      "\n",
      "Test 90\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.37181295861159\n",
      "\n",
      "Test 91\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.19021672877993\n",
      "\n",
      "Test 92\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.84139950028406\n",
      "\n",
      "Test 93\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.43586154072224\n",
      "\n",
      "Test 94\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 135.92233943303918\n",
      "\n",
      "Test 95\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 47.34532115534745\n",
      "\n",
      "Test 96\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 38.28705592451253\n",
      "\n",
      "Test 97\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 36.48042381384583\n",
      "\n",
      "Test 98\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.94288325905509\n",
      "\n",
      "Test 99\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.47106970422748\n",
      "\n",
      "Test 100\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.25734996733938\n",
      "\n",
      "Test 101\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.65892801634437\n",
      "\n",
      "Test 102\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.83926934053963\n",
      "\n",
      "Test 103\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 39.7927752137421\n",
      "\n",
      "Test 104\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.17704862431732\n",
      "\n",
      "Test 105\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 34.906931548701166\n",
      "\n",
      "Test 106\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 35.04006293422518\n",
      "\n",
      "Test 107\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 37.91027530698096\n",
      "\n",
      "Test 108\n",
      "Predict: 2\n",
      "Actual: 2\n",
      "Rank 39.3558446877491\n",
      "\n",
      "Spam Dataset\n",
      "Accuracy : 32/34 = 0.9411764705882353\n",
      "\n",
      "Not Important Dataset\n",
      "Accuracy : 0/34 = 0.0\n",
      "\n",
      "Important Dataset\n",
      "Accuracy : 40/40 = 1.0\n",
      "\n",
      "Total Accuracy : 72/108 = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "correct = {\n",
    "    0: [0,0], # number of correctly predicted, total number of spam dataset\n",
    "    1: [0,0],\n",
    "    2: [0,0],\n",
    "}\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    correct[df.iloc[i, :].label][1] += 1\n",
    "    spam = checkSpam(pd.DataFrame(df.iloc[[i]]))\n",
    "    result = None\n",
    "    res = None\n",
    "    if spam:\n",
    "        result = 0\n",
    "    \n",
    "    if not spam:\n",
    "        # tokenization\n",
    "        res = rank_message(df.iloc[i, :])\n",
    "        result = 2 if (res[0] > 9.009694517030455) else 1\n",
    "    if result == df.iloc[i, :].label: correct[df.iloc[i, :].label][0] += 1\n",
    "    print(f\"Test {i+1}\\nPredict: {result}\\nActual: {(df.iloc[i, :].label)}\")\n",
    "    if res is not None: print(f\"Rank {res[0]}\")\n",
    "    print()\n",
    "\n",
    "print(\"Spam Dataset\")\n",
    "print(f\"Accuracy : {correct[0][0]}/{correct[0][1]} = {correct[0][0] / correct[0][1]}\")\n",
    "print()\n",
    "print(\"Not Important Dataset\")\n",
    "print(f\"Accuracy : {correct[1][0]}/{correct[1][1]} = {correct[1][0] / correct[1][1]}\")\n",
    "print()\n",
    "print(\"Important Dataset\")\n",
    "print(f\"Accuracy : {correct[2][0]}/{correct[2][1]} = {correct[2][0] / correct[2][1]}\")\n",
    "print()\n",
    "print(f\"Total Accuracy : {correct[0][0] + correct[1][0] + correct[2][0]}/{correct[0][1] + correct[1][1] + correct[2][1]} = {(correct[0][0] + correct[1][0] + correct[2][0]) / (correct[0][1] + correct[1][1] + correct[2][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5352401,
     "sourceId": 8903029,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5355237,
     "sourceId": 8906774,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

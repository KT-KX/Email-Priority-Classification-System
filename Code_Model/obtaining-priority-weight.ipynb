{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":808042,"sourceType":"datasetVersion","datasetId":423767},{"sourceId":8899118,"sourceType":"datasetVersion","datasetId":5350087}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install and import all necessaries libraries","metadata":{}},{"cell_type":"code","source":"pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:33:29.085575Z","iopub.execute_input":"2024-07-08T05:33:29.085860Z","iopub.status.idle":"2024-07-08T05:33:41.241612Z","shell.execute_reply.started":"2024-07-08T05:33:29.085833Z","shell.execute_reply":"2024-07-08T05:33:41.240465Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:33:41.246642Z","iopub.execute_input":"2024-07-08T05:33:41.246986Z","iopub.status.idle":"2024-07-08T05:33:41.954174Z","shell.execute_reply.started":"2024-07-08T05:33:41.246949Z","shell.execute_reply":"2024-07-08T05:33:41.953422Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Used to install wordnet lemmatizer\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:33:41.955247Z","iopub.execute_input":"2024-07-08T05:33:41.955541Z","iopub.status.idle":"2024-07-08T05:34:06.214902Z","shell.execute_reply.started":"2024-07-08T05:33:41.955517Z","shell.execute_reply":"2024-07-08T05:34:06.213952Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer \nimport numpy as np\nimport pandas as pd\nimport nltk\nimport os\nimport string\n\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:06.217965Z","iopub.execute_input":"2024-07-08T05:34:06.218290Z","iopub.status.idle":"2024-07-08T05:34:06.622067Z","shell.execute_reply.started":"2024-07-08T05:34:06.218240Z","shell.execute_reply":"2024-07-08T05:34:06.621095Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import time, sys\nfrom IPython.display import clear_output\ndef update_progress(progress):\n    bar_length = 20\n    if isinstance(progress, int):\n        progress = float(progress)\n    if not isinstance(progress, float):\n        progress = 0\n    if progress < 0:\n        progress = 0\n    if progress >= 1:\n        progress = 1\n    block = int(round(bar_length * progress))\n    clear_output(wait = True)\n    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n    print(text)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:06.623332Z","iopub.execute_input":"2024-07-08T05:34:06.623729Z","iopub.status.idle":"2024-07-08T05:34:06.630223Z","shell.execute_reply.started":"2024-07-08T05:34:06.623703Z","shell.execute_reply":"2024-07-08T05:34:06.629323Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Import dataset into the notebook","metadata":{}},{"cell_type":"markdown","source":"We will only be considering the ham dataset as spam dataset is not a priority to the user.","metadata":{}},{"cell_type":"code","source":"directories = [\n    '/kaggle/input/enron-spam/enron1/ham',\n    '/kaggle/input/enron-spam/enron2/ham',\n    '/kaggle/input/enron-spam/enron3/ham',\n    '/kaggle/input/enron-spam/enron4/ham',\n    '/kaggle/input/enron-spam/enron5/ham',\n    '/kaggle/input/enron-spam/enron6/ham',\n]\n\ndef get_data_from_directories(directories):\n    combined_data = []\n    \n    for directory in directories:\n        label = os.path.basename(directory)  # Extract the directory name as the label\n        for root, dirs, files in os.walk(directory):\n            for file in files:\n                file_path = os.path.join(root, file)\n                with open(file_path, 'r', encoding='ISO-8859-1') as f:\n                    content = f.read()\n                    combined_data.append({'text': content, 'label': label})\n    \n    return combined_data\n\n# Get data from all directories\ncombined_data = get_data_from_directories(directories)\n\nimport numpy as np\n\n# Create a DataFrame\ndf = pd.DataFrame(combined_data)\n\n# Check the first few rows of the DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:06.631516Z","iopub.execute_input":"2024-07-08T05:34:06.631850Z","iopub.status.idle":"2024-07-08T05:34:29.808625Z","shell.execute_reply.started":"2024-07-08T05:34:06.631820Z","shell.execute_reply":"2024-07-08T05:34:29.807684Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text label\n0  Subject: hilcorp old ocean\\ni have continued t...   ham\n1  Subject: meter 6461 , concorde churchill\\none ...   ham\n2  Subject: 6 / 15 / 00 revision to sea robin vol...   ham\n3  Subject: natural gas nomination for 05 / 00\\ne...   ham\n4  Subject: november prelim wellhead production -...   ham","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Subject: hilcorp old ocean\\ni have continued t...</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Subject: meter 6461 , concorde churchill\\none ...</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Subject: 6 / 15 / 00 revision to sea robin vol...</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subject: natural gas nomination for 05 / 00\\ne...</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Subject: november prelim wellhead production -...</td>\n      <td>ham</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Experimenting phase","metadata":{}},{"cell_type":"markdown","source":"Playing around with the data to observe its structure","metadata":{}},{"cell_type":"code","source":"# Checking the first subject data\ndf.iloc[0,0]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:29.809884Z","iopub.execute_input":"2024-07-08T05:34:29.810548Z","iopub.status.idle":"2024-07-08T05:34:29.816725Z","shell.execute_reply.started":"2024-07-08T05:34:29.810510Z","shell.execute_reply":"2024-07-08T05:34:29.815911Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'Subject: hilcorp old ocean\\ni have continued the hilcorp old ocean deal . dan hyvl is writing up the\\ncontracts for me and they should be ready monday . terms are as follows :\\nsept - nov 2000\\nifhsc + . 02\\ngas daily for any mid month turn on as in our purchase contracts\\nletter of credit must be approved prior to sept 1 ( they said they will have\\nit monday by 2 pm )\\nvolume min / max is 7 , 000 / day - 20 , 000 / day with same tolerance currently\\nexisting for swing . ( we expect to level out around 10 , 000 / d )\\nplease call if you have any concerns as we will continue this gas flow\\nwithout interruption . thanks , mary jo johnson'"},"metadata":{}}]},{"cell_type":"code","source":"# Experimenting on splitting a single long line text into multiple line\ndf.iloc[1,0].split('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:29.817894Z","iopub.execute_input":"2024-07-08T05:34:29.818214Z","iopub.status.idle":"2024-07-08T05:34:29.830833Z","shell.execute_reply.started":"2024-07-08T05:34:29.818184Z","shell.execute_reply":"2024-07-08T05:34:29.830038Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Subject: meter 6461 , concorde churchill',\n \"one year rate for this one will be $ . 35 / mm for volumes greater than 300 mm / day . price for volumes 300 mm / day or less will be $ . 45 / mm plus a $ 350 per month metering fee . this rate would cover transport to a competitive ship channel market such as equistar channelview . transport rates for a 6 month term are not significantly different - $ . 33 / mm for volumes greater than 300 mm / day and $ . 42 / mm plus the metering fee for volumes 300 mm / day or less . these rates assume a september 1 , 2001 start . these rates good until friday , august 31 , 2001 only ! ! ! get ' em while they ' re hot ! !\"]"},"metadata":{}}]},{"cell_type":"markdown","source":"We will extract all information and organize it into their respective categories (for exp: sender, recipient, date, subject, content)","metadata":{}},{"cell_type":"code","source":"def extract_email_info(email_text):\n    lines = email_text.split('\\n')\n\n    content = ''\n    sender = ''\n    recipient = ''\n    subject = ''\n    date = ''\n\n    for line in lines:\n        if line.startswith('Subject:'):\n            subject = line.replace('Subject:', '').strip()\n        elif line.startswith('From:'):\n            sender = line.replace('From:', '').strip()\n        elif line.startswith('To:'):\n            recipient = line.replace('To:', '').strip()\n        elif line.startswith('Date:'):\n            date = line.replace('Date:', '').strip()\n        elif line.startswith('Received:'):\n            date = line.replace('Received:', '').strip()\n        elif line.startswith('X-'):\n            continue\n        else:\n            content += line.strip()\n\n    return {'sender': sender, 'recipient': recipient, 'subject': subject, 'date': date, 'content': content}\n\n# Applying the function to the DataFrame\ndf['extracted_info'] = df['text'].apply(extract_email_info)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:29.831919Z","iopub.execute_input":"2024-07-08T05:34:29.832241Z","iopub.status.idle":"2024-07-08T05:34:30.295225Z","shell.execute_reply.started":"2024-07-08T05:34:29.832209Z","shell.execute_reply":"2024-07-08T05:34:30.294468Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['extracted_info']","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:30.296369Z","iopub.execute_input":"2024-07-08T05:34:30.296713Z","iopub.status.idle":"2024-07-08T05:34:30.306523Z","shell.execute_reply.started":"2024-07-08T05:34:30.296681Z","shell.execute_reply":"2024-07-08T05:34:30.305613Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0        {'sender': '', 'recipient': '', 'subject': 'hi...\n1        {'sender': '', 'recipient': '', 'subject': 'me...\n2        {'sender': '', 'recipient': '', 'subject': '6 ...\n3        {'sender': '', 'recipient': '', 'subject': 'na...\n4        {'sender': '', 'recipient': '', 'subject': 'no...\n                               ...                        \n16540    {'sender': '', 'recipient': '', 'subject': 'pr...\n16541    {'sender': '', 'recipient': '', 'subject': 'et...\n16542    {'sender': '', 'recipient': '', 'subject': 'el...\n16543    {'sender': '', 'recipient': '', 'subject': 're...\n16544    {'sender': '', 'recipient': '', 'subject': 'fw...\nName: extracted_info, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[['sender', 'recipient', 'subject', 'date', 'content']] = df['extracted_info'].apply(pd.Series)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:30.307644Z","iopub.execute_input":"2024-07-08T05:34:30.307930Z","iopub.status.idle":"2024-07-08T05:34:34.039566Z","shell.execute_reply.started":"2024-07-08T05:34:30.307902Z","shell.execute_reply":"2024-07-08T05:34:34.038525Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.040725Z","iopub.execute_input":"2024-07-08T05:34:34.041007Z","iopub.status.idle":"2024-07-08T05:34:34.067126Z","shell.execute_reply.started":"2024-07-08T05:34:34.040983Z","shell.execute_reply":"2024-07-08T05:34:34.066236Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16545 entries, 0 to 16544\nData columns (total 8 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   text            16545 non-null  object\n 1   label           16545 non-null  object\n 2   extracted_info  16545 non-null  object\n 3   sender          16545 non-null  object\n 4   recipient       16545 non-null  object\n 5   subject         16545 non-null  object\n 6   date            16545 non-null  object\n 7   content         16545 non-null  object\ndtypes: object(8)\nmemory usage: 1.0+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's check to see if there's any value in those categories","metadata":{}},{"cell_type":"code","source":"df['recipient'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.073041Z","iopub.execute_input":"2024-07-08T05:34:34.073727Z","iopub.status.idle":"2024-07-08T05:34:34.080328Z","shell.execute_reply.started":"2024-07-08T05:34:34.073685Z","shell.execute_reply":"2024-07-08T05:34:34.079483Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([''], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"sender\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.081419Z","iopub.execute_input":"2024-07-08T05:34:34.081699Z","iopub.status.idle":"2024-07-08T05:34:34.092010Z","shell.execute_reply.started":"2024-07-08T05:34:34.081675Z","shell.execute_reply":"2024-07-08T05:34:34.091061Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([''], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"date\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.093161Z","iopub.execute_input":"2024-07-08T05:34:34.093830Z","iopub.status.idle":"2024-07-08T05:34:34.100940Z","shell.execute_reply.started":"2024-07-08T05:34:34.093804Z","shell.execute_reply":"2024-07-08T05:34:34.100252Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([''], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"subject\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.101840Z","iopub.execute_input":"2024-07-08T05:34:34.102704Z","iopub.status.idle":"2024-07-08T05:34:34.116559Z","shell.execute_reply.started":"2024-07-08T05:34:34.102678Z","shell.execute_reply":"2024-07-08T05:34:34.115627Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array(['hilcorp old ocean', 'meter 6461 , concorde churchill',\n       '6 / 15 / 00 revision to sea robin volumes', ...,\n       'proposed decision', 'el paso starts line 2000 conversion',\n       'fw : socal rls / peaking tariff'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"content\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.117596Z","iopub.execute_input":"2024-07-08T05:34:34.117941Z","iopub.status.idle":"2024-07-08T05:34:34.177588Z","shell.execute_reply.started":"2024-07-08T05:34:34.117830Z","shell.execute_reply":"2024-07-08T05:34:34.176786Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array(['i have continued the hilcorp old ocean deal . dan hyvl is writing up thecontracts for me and they should be ready monday . terms are as follows :sept - nov 2000ifhsc + . 02gas daily for any mid month turn on as in our purchase contractsletter of credit must be approved prior to sept 1 ( they said they will haveit monday by 2 pm )volume min / max is 7 , 000 / day - 20 , 000 / day with same tolerance currentlyexisting for swing . ( we expect to level out around 10 , 000 / d )please call if you have any concerns as we will continue this gas flowwithout interruption . thanks , mary jo johnson',\n       \"one year rate for this one will be $ . 35 / mm for volumes greater than 300 mm / day . price for volumes 300 mm / day or less will be $ . 45 / mm plus a $ 350 per month metering fee . this rate would cover transport to a competitive ship channel market such as equistar channelview . transport rates for a 6 month term are not significantly different - $ . 33 / mm for volumes greater than 300 mm / day and $ . 42 / mm plus the metering fee for volumes 300 mm / day or less . these rates assume a september 1 , 2001 start . these rates good until friday , august 31 , 2001 only ! ! ! get ' em while they ' re hot ! !\",\n       '- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 06 / 19 / 200003 : 30 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\" steve holmes \" on 06 / 19 / 2000 03 : 10 : 42 pmto : ,cc :subject : 6 / 15 / 00 revision to sea robin volumeschristina ,the attached shows the volumes that should have been nominated effective6 / 15 / 00 and 6 / 16 / 00 . the sea robin plant was back up for those two days andgas was processed resulting in a decrease for pvr . effective 6 / 17 / 00 , theplant was down again and volumes were increased to reflect no processingloss . i forwarded those volumes to you on friday , june 16 .let me know of any questions you have .thanks ,steve- ei 305 reveffo 61500 . xls- ei 330 areveffo 61500 . xls- ei 330 breveffo 61500 . xls- ei 330 creveffo 61500 . xls- ei 333 reveffo 61500 . xls- ei 337 reveffo 61500 . xls- smi 23 reveffo 61500 . xls- smi 41 reveffo 61500 . xls- smil 28 reveffo 61500 . xls- wc 560 reveffo 61500 . xls- wc 580 reveffo 61500 . xls- gbl 28 reveffo 61500 . xls',\n       ...,\n       'el paso shines up line 2000 for gas conversionel paso natural gas this week received approval to begin the internal cleaning of its line 2000 , which would convert the former all american oil pipeline to gas service . the internal cleaning , or \" pigging , \" will begin at the la paz pump station , and when this portion of the conversion is completed , the project will add about 230 mmcf / d of new capacity by aug . 31 .el paso bought the line from plains all american pipeline l . p . in early 2000 . it extends 1 , 088 miles from emidio , ca , to mccamey , tx . the purchase also included any fiber optic rights that all american had along its entire 1 , 233 - mile system .el paso was awarded a federal energy regulatory commission certificate to begin the conversion project in may , and then began a binding open season for additional capacity , which extends through aug . 2 . the open season is for 230 mmcf / d of capacity from the keystone and waha areas of the permian basin in west texas to the california border near ehrenberg , az . the expansion capacity will be made available by adding compression to line 2000 from mccamey to ehrenberg , with a projected in - service date of mid - 2003 .',\n       'can we gas control make an assumption that no gas will flow until efm isinstalled . we need this info . to balance our system .dsbob burleson11 / 08 / 2000 07 : 29 amto : earl chanley / et & s / enron @ enroncc : mike mccracken / et & s / enron @ enron , darrell schoolcraft / et & s / enron @ enron ,\" laura j . kunkel \" , perryfrazier / et & s / enron @ enron , michelle lokay / et & s / enron @ enronsubject : re : eog pronghorn locationif we bare any expense , eog is suppose to reimburse us , but getting money outof them is like pulling teeth .i suggest we complete the work at the site and have our facilities ready toproceed when necessary . marketing is not in a position right now to pay thecost of the efm . given that these volumes will flow under a \" poolingagreement \" , there isn \\' t any incremental revenue generated for tw .we will get with eog to request payment for the efm before we proceed . anyidea how much the efm will cost ?',\n       \"fyi , kim .- - - - - original message - - - - -from : hass , glensent : thu 8 / 2 / 2001 3 : 42 pmto : harris , steven ; fossum , drew ; miller , mary kay ; watson , kimberlycc :subject : socal rls / peaking tariffin the cpuc ' s meeting today , the commission approved the proposed rls / peaking tariff which provides for a bypass peaking rate when customers bypass their system except for peaking service . it appears they approved the june 19 th proposed decision which establishes a cost based rate made up of four components - - customer charge , public purpose program charge , reservation charge and a volumetric interstate transition cost surcharge . as soon as the order is published i ' ll review the final order and advise if this is still true or if any changes were made . socal will have 10 days from the order to file an advice letter with conforming tariff sheets .gh\"],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"Apparently, we can see that the only useful information we can get is in subject category and content category as the rest of the categories have only empty data","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:04:18.373315Z","iopub.execute_input":"2024-07-07T16:04:18.374130Z","iopub.status.idle":"2024-07-07T16:04:18.395484Z","shell.execute_reply.started":"2024-07-07T16:04:18.374093Z","shell.execute_reply":"2024-07-07T16:04:18.394525Z"}}},{"cell_type":"markdown","source":"# Preprocessing ","metadata":{}},{"cell_type":"markdown","source":"Now that we have extracted, organized and understood the structure of our data, we can begin our preprocessing phase to preprocess our data.\nFirst step of preprocessing will be tokenization","metadata":{}},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"df[\"subject\"] = df[\"subject\"].apply(nltk.word_tokenize)\ndf[\"subject\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:34.178599Z","iopub.execute_input":"2024-07-08T05:34:34.178862Z","iopub.status.idle":"2024-07-08T05:34:36.387706Z","shell.execute_reply.started":"2024-07-08T05:34:34.178825Z","shell.execute_reply":"2024-07-08T05:34:36.386730Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0                                    [hilcorp, old, ocean]\n1                    [meter, 6461, ,, concorde, churchill]\n2        [6, /, 15, /, 00, revision, to, sea, robin, vo...\n3               [natural, gas, nomination, for, 05, /, 00]\n4        [november, prelim, wellhead, production, -, es...\n                               ...                        \n16540                                 [proposed, decision]\n16541                    [etc, -, event, -, schlitterbahn]\n16542           [el, paso, starts, line, 2000, conversion]\n16543                    [re, :, eog, pronghorn, location]\n16544              [fw, :, socal, rls, /, peaking, tariff]\nName: subject, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[\"content\"] = df[\"content\"].apply(nltk.word_tokenize)\ndf[\"content\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:34:36.388796Z","iopub.execute_input":"2024-07-08T05:34:36.389076Z","iopub.status.idle":"2024-07-08T05:35:32.765227Z","shell.execute_reply.started":"2024-07-08T05:34:36.389051Z","shell.execute_reply":"2024-07-08T05:35:32.764311Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0        [i, have, continued, the, hilcorp, old, ocean,...\n1        [one, year, rate, for, this, one, will, be, $,...\n2        [-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...\n3        [enron, methanol, nominates, the, following, n...\n4        [daren, ,, fyi, .bob-, -, -, -, -, -, -, -, -,...\n                               ...                        \n16540    [the, gd, article, today, regarding, the, prop...\n16541    [good, news, !, !, !, !, !, i, contacted, schl...\n16542    [el, paso, shines, up, line, 2000, for, gas, c...\n16543    [can, we, gas, control, make, an, assumption, ...\n16544    [fyi, ,, kim, .-, -, -, -, -, original, messag...\nName: content, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"Next will be stop word, punctuation and digit removal process\nThese steps are required to remove unimportant features to ease the training process","metadata":{}},{"cell_type":"markdown","source":"## Stop word + Punctuation + Digit removal\n","metadata":{}},{"cell_type":"code","source":"def remove_unwanted_words(x):\n    res = []\n    for i, word in enumerate(x):\n        if word.isdigit():\n            continue\n        if word not in unwanted_words:\n            res.append(word)\n            continue\n        if i == 0 and (word in [\"re\", \"fw\"]):\n            res.append(word)\n            continue\n    return res\n\nunwanted_words = [] + list(nltk.corpus.stopwords.words(\"english\")) + list(string.punctuation)\n            \n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:32.766354Z","iopub.execute_input":"2024-07-08T05:35:32.766648Z","iopub.status.idle":"2024-07-08T05:35:32.774510Z","shell.execute_reply.started":"2024-07-08T05:35:32.766624Z","shell.execute_reply":"2024-07-08T05:35:32.773640Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df[\"subject\"] = df[\"subject\"].apply(remove_unwanted_words)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:32.775802Z","iopub.execute_input":"2024-07-08T05:35:32.776130Z","iopub.status.idle":"2024-07-08T05:35:33.062682Z","shell.execute_reply.started":"2024-07-08T05:35:32.776099Z","shell.execute_reply":"2024-07-08T05:35:33.061966Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df[\"content\"] = df[\"content\"].apply(remove_unwanted_words)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:33.063668Z","iopub.execute_input":"2024-07-08T05:35:33.063935Z","iopub.status.idle":"2024-07-08T05:35:45.881935Z","shell.execute_reply.started":"2024-07-08T05:35:33.063911Z","shell.execute_reply":"2024-07-08T05:35:45.881151Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df[\"subject\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:45.883097Z","iopub.execute_input":"2024-07-08T05:35:45.883464Z","iopub.status.idle":"2024-07-08T05:35:45.895194Z","shell.execute_reply.started":"2024-07-08T05:35:45.883428Z","shell.execute_reply":"2024-07-08T05:35:45.894298Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0                                    [hilcorp, old, ocean]\n1                             [meter, concorde, churchill]\n2                          [revision, sea, robin, volumes]\n3                               [natural, gas, nomination]\n4        [november, prelim, wellhead, production, estim...\n                               ...                        \n16540                                 [proposed, decision]\n16541                          [etc, event, schlitterbahn]\n16542                 [el, paso, starts, line, conversion]\n16543                       [re, eog, pronghorn, location]\n16544                    [fw, socal, rls, peaking, tariff]\nName: subject, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[\"content\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:45.896544Z","iopub.execute_input":"2024-07-08T05:35:45.897281Z","iopub.status.idle":"2024-07-08T05:35:45.912273Z","shell.execute_reply.started":"2024-07-08T05:35:45.897229Z","shell.execute_reply":"2024-07-08T05:35:45.911494Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0        [continued, hilcorp, old, ocean, deal, dan, hy...\n1        [one, year, rate, one, mm, volumes, greater, m...\n2        [forwarded, ami, chokshi, corp, enron, pm, '',...\n3        [enron, methanol, nominates, following, natura...\n4        [daren, fyi, .bob-, forwarded, robert, cotten,...\n                               ...                        \n16540    [gd, article, today, regarding, proposed, deci...\n16541    [good, news, contacted, schlitterbahn, two, da...\n16542    [el, paso, shines, line, gas, conversionel, pa...\n16543    [gas, control, make, assumption, gas, flow, ef...\n16544    [fyi, kim, .-, original, message, -from, hass,...\nName: content, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"Next will be lemmatization process. We will be changing everything into its root form to remain consistent and make the training process easier","metadata":{}},{"cell_type":"markdown","source":"## Lemmatization","metadata":{}},{"cell_type":"code","source":"def lemmatization(x):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(token) for token in x]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:45.913184Z","iopub.execute_input":"2024-07-08T05:35:45.913533Z","iopub.status.idle":"2024-07-08T05:35:45.921291Z","shell.execute_reply.started":"2024-07-08T05:35:45.913507Z","shell.execute_reply":"2024-07-08T05:35:45.920322Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df[\"subject\"] = df[\"subject\"].apply(lemmatization)\ndf[\"subject\"] = df[\"subject\"].apply(\" \".join)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:45.922611Z","iopub.execute_input":"2024-07-08T05:35:45.923410Z","iopub.status.idle":"2024-07-08T05:35:48.685762Z","shell.execute_reply.started":"2024-07-08T05:35:45.923366Z","shell.execute_reply":"2024-07-08T05:35:48.684997Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df[\"content\"] = df[\"content\"].apply(lemmatization)\ndf[\"content\"] = df[\"content\"].apply(\" \".join)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:35:48.686806Z","iopub.execute_input":"2024-07-08T05:35:48.687095Z","iopub.status.idle":"2024-07-08T05:36:02.869331Z","shell.execute_reply.started":"2024-07-08T05:35:48.687069Z","shell.execute_reply":"2024-07-08T05:36:02.868497Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df[\"content\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.870435Z","iopub.execute_input":"2024-07-08T05:36:02.870730Z","iopub.status.idle":"2024-07-08T05:36:02.878445Z","shell.execute_reply.started":"2024-07-08T05:36:02.870705Z","shell.execute_reply":"2024-07-08T05:36:02.877493Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0        continued hilcorp old ocean deal dan hyvl writ...\n1        one year rate one mm volume greater mm day pri...\n2        forwarded ami chokshi corp enron pm '' steve h...\n3        enron methanol nominates following natural gas...\n4        daren fyi .bob- forwarded robert cotten hou ec...\n                               ...                        \n16540    gd article today regarding proposed decision p...\n16541    good news contacted schlitterbahn two day tick...\n16542    el paso shine line gas conversionel paso natur...\n16543    gas control make assumption gas flow efm isins...\n16544    fyi kim .- original message -from ha glensent ...\nName: content, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[\"subject\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.879517Z","iopub.execute_input":"2024-07-08T05:36:02.879820Z","iopub.status.idle":"2024-07-08T05:36:02.890716Z","shell.execute_reply.started":"2024-07-08T05:36:02.879782Z","shell.execute_reply":"2024-07-08T05:36:02.889839Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0                                   hilcorp old ocean\n1                            meter concorde churchill\n2                           revision sea robin volume\n3                              natural gas nomination\n4        november prelim wellhead production estimate\n                             ...                     \n16540                               proposed decision\n16541                         etc event schlitterbahn\n16542                   el paso start line conversion\n16543                       re eog pronghorn location\n16544                     fw socal rls peaking tariff\nName: subject, Length: 16545, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Weight Learning ","metadata":{}},{"cell_type":"markdown","source":"Now that we have preprocessed the email data, we can begin ranking our email by first learning the weight. More weight will be placed in features that are deemed as important\n\nThere are 3 types of weight that we will be learning. \nThe first weight will depend on how active our thread is\nThe second will depend on the term used in active thread\nThe third will depeon on the frequent term used in all emails","metadata":{}},{"cell_type":"markdown","source":"## First weight","metadata":{}},{"cell_type":"markdown","source":"To consider whether a thread is active, we can observe the frequency of the email by looking at the subject line. Multiple emails with the same subject line (or subject line with \"re \" in the front) will indicate that it is an active thread as user keep on interacting with it, hence them keep getting email with the same subject line.\n\nOur goal is to put more weight in email with similar subject line (as they are likely to be an active thread -> important) and less weight on unfamiliar subject line","metadata":{}},{"cell_type":"code","source":"# Filter out subject that contains \"re \"\nis_thread = df.subject.str.contains('re ')\nthreads = df[is_thread]\nre_subject_split = threads[\"subject\"].apply(lambda x:x.strip(\"re \"))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.891774Z","iopub.execute_input":"2024-07-08T05:36:02.892045Z","iopub.status.idle":"2024-07-08T05:36:02.911366Z","shell.execute_reply.started":"2024-07-08T05:36:02.892022Z","shell.execute_reply":"2024-07-08T05:36:02.910619Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"threads[\"subject\"] = re_subject_split","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.912305Z","iopub.execute_input":"2024-07-08T05:36:02.912611Z","iopub.status.idle":"2024-07-08T05:36:02.919552Z","shell.execute_reply.started":"2024-07-08T05:36:02.912585Z","shell.execute_reply":"2024-07-08T05:36:02.918637Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_279/460589797.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  threads[\"subject\"] = re_subject_split\n","output_type":"stream"}]},{"cell_type":"code","source":"# get unique thread subject\nthread_subs = threads[\"subject\"].unique()\nlen(thread_subs)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.920664Z","iopub.execute_input":"2024-07-08T05:36:02.921561Z","iopub.status.idle":"2024-07-08T05:36:02.931275Z","shell.execute_reply.started":"2024-07-08T05:36:02.921527Z","shell.execute_reply":"2024-07-08T05:36:02.930432Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"2516"},"metadata":{}}]},{"cell_type":"code","source":"thread_counts = {\n    \"freq\" : [],\n    \"weight\" : []\n}\n\n# for each unique thread subject, count how many times it appear inside dataset\nfor thread in thread_subs:\n    thread_times = df.index[df.subject.str.contains(thread, regex=False) | df.subject.str.contains(\"re \" + thread, regex=False)]\n    thread_freq = len(thread_times)\n\n    if thread_freq<2:\n        thread_counts['freq'].append(np.nan)\n        thread_counts['weight'].append(np.nan)\n    else:\n        weight = thread_freq\n        log_weight = (1 + np.log10(weight))*3\n        thread_counts['freq'].append(thread_freq)\n        thread_counts['weight'].append(log_weight)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:02.932351Z","iopub.execute_input":"2024-07-08T05:36:02.932651Z","iopub.status.idle":"2024-07-08T05:36:30.278293Z","shell.execute_reply.started":"2024-07-08T05:36:02.932620Z","shell.execute_reply":"2024-07-08T05:36:30.277540Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"len(thread_counts[\"freq\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:30.279489Z","iopub.execute_input":"2024-07-08T05:36:30.279777Z","iopub.status.idle":"2024-07-08T05:36:30.285340Z","shell.execute_reply.started":"2024-07-08T05:36:30.279752Z","shell.execute_reply":"2024-07-08T05:36:30.284466Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"2516"},"metadata":{}}]},{"cell_type":"code","source":"thread_weights = pd.DataFrame(thread_counts)\nthread_weights[\"subject\"] = thread_subs\nthread_weights.dropna(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:30.286480Z","iopub.execute_input":"2024-07-08T05:36:30.286743Z","iopub.status.idle":"2024-07-08T05:36:30.297563Z","shell.execute_reply.started":"2024-07-08T05:36:30.286721Z","shell.execute_reply":"2024-07-08T05:36:30.296848Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"As you can see here, subject line that appears the most will have higher weight than those who has less frequency","metadata":{}},{"cell_type":"code","source":"thread_weights","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:30.298898Z","iopub.execute_input":"2024-07-08T05:36:30.299305Z","iopub.status.idle":"2024-07-08T05:36:30.313742Z","shell.execute_reply.started":"2024-07-08T05:36:30.299247Z","shell.execute_reply":"2024-07-08T05:36:30.313066Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"      freq    weight                                   subject\n1      2.0  3.903090  volume increase hpl meter g marshall hpl\n2      2.0  3.903090      information regarding batch noms aug\n3      2.0  3.903090                        new update buyback\n4     93.0  8.905449                                    follow\n6      2.0  3.903090            hpl meter bammel hpl p transco\n...    ...       ...                                       ...\n2491   3.0  4.431364                              cost estimat\n2499   2.0  3.903090                                 new point\n2506   7.0  5.535294                               tw capacity\n2507  18.0  6.765818                                united way\n2512   2.0  3.903090                og pronghorn material cost\n\n[1517 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>freq</th>\n      <th>weight</th>\n      <th>subject</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>volume increase hpl meter g marshall hpl</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>information regarding batch noms aug</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>new update buyback</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93.0</td>\n      <td>8.905449</td>\n      <td>follow</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>hpl meter bammel hpl p transco</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2491</th>\n      <td>3.0</td>\n      <td>4.431364</td>\n      <td>cost estimat</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>new point</td>\n    </tr>\n    <tr>\n      <th>2506</th>\n      <td>7.0</td>\n      <td>5.535294</td>\n      <td>tw capacity</td>\n    </tr>\n    <tr>\n      <th>2507</th>\n      <td>18.0</td>\n      <td>6.765818</td>\n      <td>united way</td>\n    </tr>\n    <tr>\n      <th>2512</th>\n      <td>2.0</td>\n      <td>3.903090</td>\n      <td>og pronghorn material cost</td>\n    </tr>\n  </tbody>\n</table>\n<p>1517 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Second weight","metadata":{}},{"cell_type":"markdown","source":"For the second weight, we will be focusing on the vocabulary used on the active thread (subject). We believe that word that is used in those active thread will be important (since they are active) than non active thread, hence, adding weight into it\n","metadata":{}},{"cell_type":"code","source":"vec = CountVectorizer()\nthread_tdm = vec.fit_transform(thread_weights.subject)\nthread_tdm = pd.DataFrame(thread_tdm.toarray(), columns=vec.get_feature_names_out())\nthread_tdm","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:30.314807Z","iopub.execute_input":"2024-07-08T05:36:30.315069Z","iopub.status.idle":"2024-07-08T05:36:30.360801Z","shell.execute_reply.started":"2024-07-08T05:36:30.315046Z","shell.execute_reply":"2024-07-08T05:36:30.359934Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"      abb  abi  abstract  accenture  acceptanc  access  account  accounting  \\\n0       0    0         0          0          0       0        0           0   \n1       0    0         0          0          0       0        0           0   \n2       0    0         0          0          0       0        0           0   \n3       0    0         0          0          0       0        0           0   \n4       0    0         0          0          0       0        0           0   \n...   ...  ...       ...        ...        ...     ...      ...         ...   \n1512    0    0         0          0          0       0        0           0   \n1513    0    0         0          0          0       0        0           0   \n1514    0    0         0          0          0       0        0           0   \n1515    0    0         0          0          0       0        0           0   \n1516    0    0         0          0          0       0        0           0   \n\n      acock  acquires  ...  year  yield  yo  york  youyi  yvan  zapata  \\\n0         0         0  ...     0      0   0     0      0     0       0   \n1         0         0  ...     0      0   0     0      0     0       0   \n2         0         0  ...     0      0   0     0      0     0       0   \n3         0         0  ...     0      0   0     0      0     0       0   \n4         0         0  ...     0      0   0     0      0     0       0   \n...     ...       ...  ...   ...    ...  ..   ...    ...   ...     ...   \n1512      0         0  ...     0      0   0     0      0     0       0   \n1513      0         0  ...     0      0   0     0      0     0       0   \n1514      0         0  ...     0      0   0     0      0     0       0   \n1515      0         0  ...     0      0   0     0      0     0       0   \n1516      0         0  ...     0      0   0     0      0     0       0   \n\n      zhendong  zisman  zon  \n0            0       0    0  \n1            0       0    0  \n2            0       0    0  \n3            0       0    0  \n4            0       0    0  \n...        ...     ...  ...  \n1512         0       0    0  \n1513         0       0    0  \n1514         0       0    0  \n1515         0       0    0  \n1516         0       0    0  \n\n[1517 rows x 1915 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abb</th>\n      <th>abi</th>\n      <th>abstract</th>\n      <th>accenture</th>\n      <th>acceptanc</th>\n      <th>access</th>\n      <th>account</th>\n      <th>accounting</th>\n      <th>acock</th>\n      <th>acquires</th>\n      <th>...</th>\n      <th>year</th>\n      <th>yield</th>\n      <th>yo</th>\n      <th>york</th>\n      <th>youyi</th>\n      <th>yvan</th>\n      <th>zapata</th>\n      <th>zhendong</th>\n      <th>zisman</th>\n      <th>zon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1513</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1514</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1515</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1517 rows Ã— 1915 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"term_weights = []\nfor term in vec.get_feature_names_out():\n    weight = thread_weights.weight[thread_weights.subject.str.contains(term, regex = False)].mean()\n    term_weights.append(weight)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:30.361885Z","iopub.execute_input":"2024-07-08T05:36:30.362159Z","iopub.status.idle":"2024-07-08T05:36:31.952920Z","shell.execute_reply.started":"2024-07-08T05:36:30.362135Z","shell.execute_reply":"2024-07-08T05:36:31.951967Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"thread_term_weights = pd.DataFrame.from_dict({\n    'term':vec.get_feature_names_out(),\n    'weight': term_weights\n})\n\nthread_term_weights","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:31.954063Z","iopub.execute_input":"2024-07-08T05:36:31.954375Z","iopub.status.idle":"2024-07-08T05:36:31.966482Z","shell.execute_reply.started":"2024-07-08T05:36:31.954349Z","shell.execute_reply":"2024-07-08T05:36:31.965660Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"           term    weight\n0           abb  5.033424\n1           abi  4.691726\n2      abstract  4.500000\n3     accenture  3.903090\n4     acceptanc  4.167227\n...         ...       ...\n1910       yvan  3.903090\n1911     zapata  3.903090\n1912   zhendong  4.806180\n1913     zisman  5.334454\n1914        zon  5.096910\n\n[1915 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abb</td>\n      <td>5.033424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abi</td>\n      <td>4.691726</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abstract</td>\n      <td>4.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>accenture</td>\n      <td>3.903090</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>acceptanc</td>\n      <td>4.167227</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1910</th>\n      <td>yvan</td>\n      <td>3.903090</td>\n    </tr>\n    <tr>\n      <th>1911</th>\n      <td>zapata</td>\n      <td>3.903090</td>\n    </tr>\n    <tr>\n      <th>1912</th>\n      <td>zhendong</td>\n      <td>4.806180</td>\n    </tr>\n    <tr>\n      <th>1913</th>\n      <td>zisman</td>\n      <td>5.334454</td>\n    </tr>\n    <tr>\n      <th>1914</th>\n      <td>zon</td>\n      <td>5.096910</td>\n    </tr>\n  </tbody>\n</table>\n<p>1915 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Third weight","metadata":{}},{"cell_type":"markdown","source":"For the third weight, we will be considering the term frequency in the whole email dataset. We believe that the more frequent a term appear, the more important it is to our user, hence adding more weight to that term","metadata":{}},{"cell_type":"code","source":"vec = CountVectorizer()\nmsg_tdm = vec.fit_transform(df[\"content\"])\nmsg_terms = pd.DataFrame(msg_tdm.toarray(), columns=vec.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:31.973521Z","iopub.execute_input":"2024-07-08T05:36:31.973787Z","iopub.status.idle":"2024-07-08T05:36:37.003864Z","shell.execute_reply.started":"2024-07-08T05:36:31.973764Z","shell.execute_reply":"2024-07-08T05:36:37.002833Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"msg_terms","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:37.005029Z","iopub.execute_input":"2024-07-08T05:36:37.005338Z","iopub.status.idle":"2024-07-08T05:36:37.077098Z","shell.execute_reply.started":"2024-07-08T05:36:37.005312Z","shell.execute_reply":"2024-07-08T05:36:37.076249Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"       00  000  000000000002858request  000000000003619request  \\\n0       0    0                       0                       0   \n1       0    0                       0                       0   \n2       0    0                       0                       0   \n3       0    0                       0                       0   \n4       0    0                       0                       0   \n...    ..  ...                     ...                     ...   \n16540   0    0                       0                       0   \n16541   0    0                       0                       0   \n16542   0    0                       0                       0   \n16543   0    0                       0                       0   \n16544   0    0                       0                       0   \n\n       000000000003991approver  000000000003997approver  \\\n0                            0                        0   \n1                            0                        0   \n2                            0                        0   \n3                            0                        0   \n4                            0                        0   \n...                        ...                      ...   \n16540                        0                        0   \n16541                        0                        0   \n16542                        0                        0   \n16543                        0                        0   \n16544                        0                        0   \n\n       000000000005168approver  000000000005409approver  \\\n0                            0                        0   \n1                            0                        0   \n2                            0                        0   \n3                            0                        0   \n4                            0                        0   \n...                        ...                      ...   \n16540                        0                        0   \n16541                        0                        0   \n16542                        0                        0   \n16543                        0                        0   \n16544                        0                        0   \n\n       000000000005411approver  000000000005412approver  ...  zwlaszcza  \\\n0                            0                        0  ...          0   \n1                            0                        0  ...          0   \n2                            0                        0  ...          0   \n3                            0                        0  ...          0   \n4                            0                        0  ...          0   \n...                        ...                      ...  ...        ...   \n16540                        0                        0  ...          0   \n16541                        0                        0  ...          0   \n16542                        0                        0  ...          0   \n16543                        0                        0  ...          0   \n16544                        0                        0  ...          0   \n\n       zwrocic  zwwyw  zy  zyc  zydeco  zywicki  zz  zzn  zzncacst  \n0            0      0   0    0       0        0   0    0         0  \n1            0      0   0    0       0        0   0    0         0  \n2            0      0   0    0       0        0   0    0         0  \n3            0      0   0    0       0        0   0    0         0  \n4            0      0   0    0       0        0   0    0         0  \n...        ...    ...  ..  ...     ...      ...  ..  ...       ...  \n16540        0      0   0    0       0        0   0    0         0  \n16541        0      0   0    0       0        0   0    0         0  \n16542        0      0   0    0       0        0   0    0         0  \n16543        0      0   0    0       0        0   0    0         0  \n16544        0      0   0    0       0        0   0    0         0  \n\n[16545 rows x 131355 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>000000000002858request</th>\n      <th>000000000003619request</th>\n      <th>000000000003991approver</th>\n      <th>000000000003997approver</th>\n      <th>000000000005168approver</th>\n      <th>000000000005409approver</th>\n      <th>000000000005411approver</th>\n      <th>000000000005412approver</th>\n      <th>...</th>\n      <th>zwlaszcza</th>\n      <th>zwrocic</th>\n      <th>zwwyw</th>\n      <th>zy</th>\n      <th>zyc</th>\n      <th>zydeco</th>\n      <th>zywicki</th>\n      <th>zz</th>\n      <th>zzn</th>\n      <th>zzncacst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16540</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16541</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16542</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16543</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16544</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>16545 rows Ã— 131355 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"freq = []\nfor i in vec.get_feature_names_out():\n    freq.append(msg_terms[i].sum())\nlen(freq)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:36:37.078112Z","iopub.execute_input":"2024-07-08T05:36:37.078401Z","iopub.status.idle":"2024-07-08T05:37:44.454191Z","shell.execute_reply.started":"2024-07-08T05:36:37.078377Z","shell.execute_reply":"2024-07-08T05:37:44.453279Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"131355"},"metadata":{}}]},{"cell_type":"code","source":"msg_useful_terms = pd.DataFrame.from_dict({\n    'term': vec.get_feature_names_out(),\n    'freq': freq,\n    'weight': [1 + np.log(x) for x in freq]\n})","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:44.455932Z","iopub.execute_input":"2024-07-08T05:37:44.456222Z","iopub.status.idle":"2024-07-08T05:37:45.294094Z","shell.execute_reply.started":"2024-07-08T05:37:44.456198Z","shell.execute_reply":"2024-07-08T05:37:45.293316Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"msg_useful_terms","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.295082Z","iopub.execute_input":"2024-07-08T05:37:45.295377Z","iopub.status.idle":"2024-07-08T05:37:45.306872Z","shell.execute_reply.started":"2024-07-08T05:37:45.295352Z","shell.execute_reply":"2024-07-08T05:37:45.305903Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                           term  freq    weight\n0                            00    24  4.178054\n1                           000    12  3.484907\n2        000000000002858request     1  1.000000\n3        000000000003619request     3  2.098612\n4       000000000003991approver     1  1.000000\n...                         ...   ...       ...\n131350                   zydeco     2  1.693147\n131351                  zywicki     1  1.000000\n131352                       zz     5  2.609438\n131353                      zzn     1  1.000000\n131354                 zzncacst     2  1.693147\n\n[131355 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>freq</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00</td>\n      <td>24</td>\n      <td>4.178054</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000</td>\n      <td>12</td>\n      <td>3.484907</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000000000002858request</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000000000003619request</td>\n      <td>3</td>\n      <td>2.098612</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000000000003991approver</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>131350</th>\n      <td>zydeco</td>\n      <td>2</td>\n      <td>1.693147</td>\n    </tr>\n    <tr>\n      <th>131351</th>\n      <td>zywicki</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>131352</th>\n      <td>zz</td>\n      <td>5</td>\n      <td>2.609438</td>\n    </tr>\n    <tr>\n      <th>131353</th>\n      <td>zzn</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>131354</th>\n      <td>zzncacst</td>\n      <td>2</td>\n      <td>1.693147</td>\n    </tr>\n  </tbody>\n</table>\n<p>131355 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"msg_useful_terms_without_digit = msg_useful_terms[msg_useful_terms[\"term\"].apply(lambda x:not x.isdigit())]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.308074Z","iopub.execute_input":"2024-07-08T05:37:45.308451Z","iopub.status.idle":"2024-07-08T05:37:45.369057Z","shell.execute_reply.started":"2024-07-08T05:37:45.308412Z","shell.execute_reply":"2024-07-08T05:37:45.368154Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"From here, we can see that the word \"enron\" appear the most in our email dataset, thus having the highest value of weight. This makes perfect sense since our dataset actually originate from the Enron company.","metadata":{}},{"cell_type":"code","source":"msg_useful_terms_without_digit.sort_values('weight', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.370161Z","iopub.execute_input":"2024-07-08T05:37:45.370513Z","iopub.status.idle":"2024-07-08T05:37:45.392991Z","shell.execute_reply.started":"2024-07-08T05:37:45.370481Z","shell.execute_reply":"2024-07-08T05:37:45.392208Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                           term   freq     weight\n43445                     enron  53330  11.884254\n41267                       ect  29168  11.280827\n57331                       hou  16940  10.737433\n30474                   company  13510  10.511185\n129360                    would  11770  10.373309\n...                         ...    ...        ...\n60      000000000025307approver      1   1.000000\n61       000000000025312request      1   1.000000\n47      000000000012677approver      1   1.000000\n48      000000000012734approver      1   1.000000\n49      000000000012735approver      1   1.000000\n\n[130845 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>freq</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43445</th>\n      <td>enron</td>\n      <td>53330</td>\n      <td>11.884254</td>\n    </tr>\n    <tr>\n      <th>41267</th>\n      <td>ect</td>\n      <td>29168</td>\n      <td>11.280827</td>\n    </tr>\n    <tr>\n      <th>57331</th>\n      <td>hou</td>\n      <td>16940</td>\n      <td>10.737433</td>\n    </tr>\n    <tr>\n      <th>30474</th>\n      <td>company</td>\n      <td>13510</td>\n      <td>10.511185</td>\n    </tr>\n    <tr>\n      <th>129360</th>\n      <td>would</td>\n      <td>11770</td>\n      <td>10.373309</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>000000000025307approver</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>000000000025312request</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>000000000012677approver</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>000000000012734approver</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>000000000012735approver</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>130845 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Obtain priority threshold","metadata":{}},{"cell_type":"markdown","source":"Now that we have obtained all of the necessary weights, we can begin calculating the rank of each of our emails by multiplying all related weights together. However, that will only give us a bunch of rank numbers without telling us which is email is considered as important. For that, we will have to determine the priority threshold.\n\nOur way of determining the priority threshold will be by first calculating all rank numbers for all of the emails. Then, we will pick the median of those rank numbers as our priority threshold","metadata":{}},{"cell_type":"code","source":"filtered_df = df.loc[:, ['subject', 'content']]\nfiltered_df","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.393989Z","iopub.execute_input":"2024-07-08T05:37:45.394248Z","iopub.status.idle":"2024-07-08T05:37:45.406081Z","shell.execute_reply.started":"2024-07-08T05:37:45.394225Z","shell.execute_reply":"2024-07-08T05:37:45.405131Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                                            subject  \\\n0                                 hilcorp old ocean   \n1                          meter concorde churchill   \n2                         revision sea robin volume   \n3                            natural gas nomination   \n4      november prelim wellhead production estimate   \n...                                             ...   \n16540                             proposed decision   \n16541                       etc event schlitterbahn   \n16542                 el paso start line conversion   \n16543                     re eog pronghorn location   \n16544                   fw socal rls peaking tariff   \n\n                                                 content  \n0      continued hilcorp old ocean deal dan hyvl writ...  \n1      one year rate one mm volume greater mm day pri...  \n2      forwarded ami chokshi corp enron pm '' steve h...  \n3      enron methanol nominates following natural gas...  \n4      daren fyi .bob- forwarded robert cotten hou ec...  \n...                                                  ...  \n16540  gd article today regarding proposed decision p...  \n16541  good news contacted schlitterbahn two day tick...  \n16542  el paso shine line gas conversionel paso natur...  \n16543  gas control make assumption gas flow efm isins...  \n16544  fyi kim .- original message -from ha glensent ...  \n\n[16545 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hilcorp old ocean</td>\n      <td>continued hilcorp old ocean deal dan hyvl writ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>meter concorde churchill</td>\n      <td>one year rate one mm volume greater mm day pri...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>revision sea robin volume</td>\n      <td>forwarded ami chokshi corp enron pm '' steve h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>natural gas nomination</td>\n      <td>enron methanol nominates following natural gas...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>november prelim wellhead production estimate</td>\n      <td>daren fyi .bob- forwarded robert cotten hou ec...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16540</th>\n      <td>proposed decision</td>\n      <td>gd article today regarding proposed decision p...</td>\n    </tr>\n    <tr>\n      <th>16541</th>\n      <td>etc event schlitterbahn</td>\n      <td>good news contacted schlitterbahn two day tick...</td>\n    </tr>\n    <tr>\n      <th>16542</th>\n      <td>el paso start line conversion</td>\n      <td>el paso shine line gas conversionel paso natur...</td>\n    </tr>\n    <tr>\n      <th>16543</th>\n      <td>re eog pronghorn location</td>\n      <td>gas control make assumption gas flow efm isins...</td>\n    </tr>\n    <tr>\n      <th>16544</th>\n      <td>fw socal rls peaking tariff</td>\n      <td>fyi kim .- original message -from ha glensent ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>16545 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"filtered_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.407161Z","iopub.execute_input":"2024-07-08T05:37:45.407482Z","iopub.status.idle":"2024-07-08T05:37:45.415129Z","shell.execute_reply.started":"2024-07-08T05:37:45.407459Z","shell.execute_reply":"2024-07-08T05:37:45.414309Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(16545, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"Since the process of ranking every email takes way too much training time, we will be performing the priority threshold observation in another notebook","metadata":{}},{"cell_type":"code","source":"thread_weights.to_csv(\"thread_weights.csv\", index = False)\nthread_term_weights.to_csv(\"thread_term_weights.csv\", index = False)\nmsg_useful_terms_without_digit.to_csv(\"msg_useful_terms_without_digit.csv\", index = False)\nfiltered_df.to_csv(\"filtered_df.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:37:45.416092Z","iopub.execute_input":"2024-07-08T05:37:45.416349Z","iopub.status.idle":"2024-07-08T05:37:46.518105Z","shell.execute_reply.started":"2024-07-08T05:37:45.416327Z","shell.execute_reply":"2024-07-08T05:37:46.517095Z"},"trusted":true},"execution_count":49,"outputs":[]}]}